{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\caisplusplus\\env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\caisplusplus\\env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\caisplusplus\\env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\caisplusplus\\env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\caisplusplus\\env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\caisplusplus\\env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\caisplusplus\\env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\caisplusplus\\env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\caisplusplus\\env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\caisplusplus\\env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\caisplusplus\\env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\caisplusplus\\env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import TextArea, AnnotationBbox, OffsetImage\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, MaxPool2D, Dense, Flatten, Reshape\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[train_labels[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the images\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Add a channel dimension of size 1\n",
    "# (We only need 1 channel because the images are black and white)\n",
    "train_images = train_images.reshape(60000, 28, 28, 1)\n",
    "test_images = test_images.reshape(10000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the encoder CNN using the tf.Keras functional API\n",
    "# It should 2 conv/pool layers and a dense layer\n",
    "def create_encoder(input_shape, encoding_dim):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    conv1 = Conv2D(32, 3, padding=\"same\", activation=\"relu\")(inputs)\n",
    "    pool1 = MaxPool2D()(conv1)\n",
    "    conv2 = Conv2D(64, 3, padding=\"same\", activation=\"relu\")(pool1)\n",
    "    pool2 = MaxPool2D()(conv2)\n",
    "    flatten = Flatten()(pool2)\n",
    "    dense = Dense(encoding_dim, activation=\"softmax\")(flatten)\n",
    "    \n",
    "    encoder = Model(inputs, dense)\n",
    "    encoder.summary()\n",
    "    \n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the decoder CNN using the tf.Keras functional API\n",
    "# It should a reshape layer, 2 conv transpose layers, and a pixel-wise conv layer\n",
    "def create_decoder(encoding_dim):\n",
    "    if not sqrt(encoding_dim).is_integer():\n",
    "        raise ValueError(\"Encoding dim must be a perfect square.\")\n",
    "    \n",
    "    inputs = Input(shape=encoding_dim)\n",
    "    reshape = Reshape((int(sqrt(encoding_dim)), int(sqrt(encoding_dim)), 1))(inputs)\n",
    "    conv1 = Conv2DTranspose(64, 3, strides=2, padding=\"same\", activation=\"relu\")(reshape)\n",
    "    conv2 = Conv2DTranspose(32, 3, strides=2, padding=\"same\", activation=\"relu\")(conv1)\n",
    "    conv3 = Conv2D(1, 3, padding=\"same\", activation=\"sigmoid\")(conv2)\n",
    "    \n",
    "    decoder = Model(inputs, conv3)\n",
    "    decoder.summary()\n",
    "    \n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = train_images[0].shape\n",
    "encoding_dim = 49 # Why did I pick 49?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the encoder and the decoder\n",
    "encoder = create_encoder(input_shape, encoding_dim)\n",
    "decoder = create_decoder(encoding_dim)\n",
    "\n",
    "# Define the autoencoder architecture using the tf.Keras functional API\n",
    "# Recall that it goes input -> encoder -> decoder\n",
    "inputs = Input(shape=input_shape)\n",
    "encoded = encoder(inputs)\n",
    "decoded = decoder(encoded)\n",
    "\n",
    "# Create and compile the autoencoder model\n",
    "# Which loss function? (See slides)\n",
    "autoencoder = Model(inputs, decoded)\n",
    "autoencoder.summary()\n",
    "\n",
    "autoencoder.compile(optimizer=\"adam\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model for 250 epochs (make sure you're on the GPU)\n",
    "autoencoder.fit(train_images, train_images, batch_size=256, epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss = autoencoder.evaluate(test_images, test_images, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on 5 images from the test set\n",
    "# Store the predictions in a variable called preds\n",
    "visual = test_images[:5]\n",
    "preds = autoencoder.predict(visual)\n",
    "\n",
    "# This plots the original and reconstructed images\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(5):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(test_images[i].squeeze(), cmap=plt.cm.binary)\n",
    "    plt.xlabel(\"Original\")\n",
    "for i in range(5):\n",
    "    plt.subplot(5,5,i+6)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(preds[i].squeeze(), cmap=plt.cm.binary)\n",
    "    plt.xlabel(\"Reconstructed\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function plots the latent space of the autoencoder\n",
    "# Note that we isolate the encoder half of the autoencoder\n",
    "# Also note that we are only plotting 2 dimensions of\n",
    "# a multidimensional space.\n",
    "def plot_latent(mode, count):\n",
    "    idx = np.random.choice(len(test_images), count)\n",
    "    inputs = test_images[idx]\n",
    "    fig, ax = plt.subplots(figsize=(10, 7))\n",
    "    ax.set_title(\"Autoencoder Latent Space\")\n",
    "    coords = encoder.predict(inputs)[:, :2]\n",
    "    \n",
    "    if mode == 'imgs':\n",
    "        for image, (x, y) in zip(inputs, coords):\n",
    "            im = OffsetImage(image.reshape(28, 28), zoom=1, cmap='gray')\n",
    "            ab = AnnotationBbox(im, (x, y), xycoords='data', frameon=False)\n",
    "            ax.add_artist(ab)\n",
    "        ax.update_datalim(coords)\n",
    "        ax.autoscale()\n",
    "    elif mode == 'dots':\n",
    "        classes = test_labels[idx]\n",
    "        plt.scatter(coords[:, 0], coords[:, 1], c=classes)\n",
    "        plt.colorbar()\n",
    "        for i in range(10):\n",
    "            class_center = np.mean(coords[classes == i], axis=0)\n",
    "            text = TextArea('{} ({})'.format(class_names[i], i))\n",
    "            ab = AnnotationBbox(text, class_center, xycoords='data', frameon=True)\n",
    "            ax.add_artist(ab)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the plot_latent function with different modes and counts\n",
    "# What do you observe?\n",
    "plot_latent(\"dots\", 10000)\n",
    "plot_latent(\"imgs\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try varying the architecture to correspond with different dimensions of latent space\n",
    "# What happens as the latent space becomes larger? Is there a \"sweet spot\"?\n",
    "# In particular, try with a latent space dimension of 2 to obtain the most accurate visualization\n",
    "# And try with a larger latent space dimension to obtain a more accurate prediction.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
