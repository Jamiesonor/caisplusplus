{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\caisplusplus\\env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\caisplusplus\\env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\caisplusplus\\env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\caisplusplus\\env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\caisplusplus\\env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\caisplusplus\\env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\caisplusplus\\env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\caisplusplus\\env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\caisplusplus\\env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\caisplusplus\\env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\caisplusplus\\env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\caisplusplus\\env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# In this micro-project, we'll practice using Jupyter Notebook on the server to design a CNN for\n",
    "# MNIST image classification and train it using the GPUs.\n",
    "\n",
    "# Imports various libraries (note that we are using tf.Keras, not vanilla Keras).\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import tensorflow.keras.backend as K\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Loads the MNIST dataset.\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17656f4d888>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plots an MNIST digit.\n",
    "plt.title(\"Label is {}\".format(y_train[0]))\n",
    "plt.imshow(x_train[0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (10000, 28, 28)\n",
      "(60000, 28, 28, 1) (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Preprocesses images.\n",
    "print(x_train.shape, x_test.shape)\n",
    "\n",
    "# Adds an extra dimension to the image tensor.\n",
    "# This represents the \"channels\" of the image.\n",
    "# BW images have one channel; RGB images have three.\n",
    "x_train = x_train.reshape(60000, 28, 28, 1)\n",
    "x_test = x_test.reshape(10000, 28, 28, 1)\n",
    "\n",
    "# Converts the tensors from uint8 to float32.\n",
    "# Most CNNs expect inputs of type float32.\n",
    "x_train = x_train.astype(\"float32\")\n",
    "x_test = x_test.astype(\"float32\")\n",
    "\n",
    "# Scales values to be between 0 and 1.\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,) (10000,)\n",
      "(60000, 10) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Preprocesses labels.\n",
    "print(y_train.shape, y_test.shape)\n",
    "\n",
    "# Converts labels from numbers (e.g., 7)\n",
    "# to one-hot vectors (e.g., [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]).\n",
    "\n",
    "# Q: Why is this necessary?\n",
    "# A: We can't have predictions that are in between values. Ex: if the network ouputs 2.5, this doesn't really tell us anything about what it actually predicted.\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=10)\n",
    "\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function which defines a CNN. Use the tf.Keras Functional API.\n",
    "# You'll need both convolutional and dense layers, as well as a softmax activation at the end.\n",
    "# (If you're stuck on the architecture, Slack me!)\n",
    "\n",
    "# Q: What shape is the input?\n",
    "# A: (28, 28, 1)\n",
    "\n",
    "# Q: What shape is the output?\n",
    "# A: (10)\n",
    "\n",
    "# Q: Why are we using softmax (as opposed to sigmoid)?\n",
    "# A: softmax allows for multiclass classification without training multiple binary classifiers\n",
    "\n",
    "# Q: (Bonus) How is softmax calculated (in your own words)?\n",
    "# A: Compute exponential of each softmax score and then normalize it\n",
    "\n",
    "def cnn():\n",
    "    # Your architecture here!\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Conv2D(filters=64, kernel_size=5, activation='relu', padding='same', input_shape=[28, 28, 1]),\n",
    "        keras.layers.MaxPool2D(),\n",
    "        keras.layers.Conv2D(128, 3, activation='relu', padding='same'),\n",
    "        keras.layers.Conv2D(128, 3, activation='relu', padding='same'),\n",
    "        keras.layers.MaxPool2D(),\n",
    "        keras.layers.Conv2D(256, 3, activation='relu', padding='same'),\n",
    "        keras.layers.Conv2D(256, 3, activation='relu', padding='same'),\n",
    "        keras.layers.MaxPool2D(),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(units=128, activation='relu'),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(units=64, activation='relu'),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(units=10, activation='softmax'),\n",
    "    ])\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate your CNN, then compile it with the Adam optimizer, categorical crossentropy loss, and accuracy metric.\n",
    "\n",
    "# Q: Why are we using categorical crossentropy loss?\n",
    "# A: Each image can only belong to one class\n",
    "\n",
    "# Q: (Bonus) How is categorical crossentropy loss calculated (in your own words)?\n",
    "# A: \n",
    "\n",
    "# Your code here!\n",
    "model = cnn()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 15s 243us/sample - loss: 0.3513 - acc: 0.8936\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 14s 235us/sample - loss: 0.1083 - acc: 0.9752\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 14s 237us/sample - loss: 0.0826 - acc: 0.9823\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 14s 238us/sample - loss: 0.0698 - acc: 0.9845\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 14s 237us/sample - loss: 0.0628 - acc: 0.9859\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 14s 236us/sample - loss: 0.0558 - acc: 0.9870\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 14s 239us/sample - loss: 0.0492 - acc: 0.9887\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 14s 236us/sample - loss: 0.0519 - acc: 0.9880\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 14s 235us/sample - loss: 0.0549 - acc: 0.9880\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 14s 240us/sample - loss: 0.0520 - acc: 0.9896\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 14s 240us/sample - loss: 0.0488 - acc: 0.9898\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 15s 243us/sample - loss: 0.0525 - acc: 0.9894\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 14s 240us/sample - loss: 0.0417 - acc: 0.9906\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 14s 238us/sample - loss: 0.0442 - acc: 0.9905\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 14s 239us/sample - loss: 0.0533 - acc: 0.9893\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 14s 238us/sample - loss: 0.0447 - acc: 0.9904\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 14s 240us/sample - loss: 0.0400 - acc: 0.9915\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 14s 241us/sample - loss: 0.0510 - acc: 0.9900\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 15s 243us/sample - loss: 0.0444 - acc: 0.9906\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 15s 244us/sample - loss: 0.0453 - acc: 0.9910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x178ba9ce608>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit your model for 20 epochs using the GPUs.\n",
    "\n",
    "# Q: What batch size will you use? Why?\n",
    "# A: 16, I'm not using batch normalization so my batches don't need to be too big, but I wouldn't set it >32 in any case\n",
    "\n",
    "# Your code here!\n",
    "model.fit(x_train, y_train,\n",
    "         batch_size=16,\n",
    "         epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 67us/sample - loss: 0.0526 - acc: 0.9918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05262234711186256, 0.9918]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate your model on the test dataset.\n",
    "\n",
    "# Q: Why is it necessary to separate train and test datasets?\n",
    "# A: You want to test the model on images it has never seen before.\n",
    "\n",
    "# Your code here!\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
